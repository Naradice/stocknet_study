{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKwKaQIdQyBg"
      },
      "source": [
        "Approraches\n",
        "\n",
        "1. Training a model with simulation results\n",
        "1. Training a model with another symbols\n",
        "1. Training a model with pertubation\n",
        "1. Training a model with output of statistic model\n",
        "1. Training a model with weight average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "e8LWcYfjBBO6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  IS_GOOGLE_COLAB = True\n",
        "except ImportError:\n",
        "  IS_GOOGLE_COLAB = False\n",
        "\n",
        "if IS_GOOGLE_COLAB:\n",
        "  mount_path = '/content/drive'\n",
        "  base_folder = os.path.join(mount_path, \"My Drive\", \"Data\")\n",
        "  data_folder = os.path.join(base_folder, \"FX\")\n",
        "else:\n",
        "  base_folder = '../../../Data'\n",
        "  data_folder = os.path.join(base_folder, \"FX\", \"OANDA-Japan MT5 Live\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nXPzChzz8XIq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import zipfile\n",
        "import requests\n",
        "\n",
        "def download_modlue_from_gh(repository, github_account='Naradice', branch='master', folder=None, module_path='/gdrive/My Drive/modules', **kwargs):\n",
        "  if folder is None:\n",
        "    folder = repository\n",
        "\n",
        "  zip_url = f\"https://github.com/{github_account}/{repository}/archive/refs/heads/{branch}.zip\"\n",
        "  response = requests.get(zip_url)\n",
        "  if response.status_code == 200:\n",
        "    with open(\"temp.zip\", \"wb\") as f:\n",
        "      f.write(response.content)\n",
        "    with zipfile.ZipFile(\"temp.zip\", \"r\") as zip_ref:\n",
        "      zip_ref.extractall(\"temp_dir\")\n",
        "\n",
        "    source_folder = f\"temp_dir/{repository}-{branch}/{folder}\"\n",
        "    destination_folder = os.path.join(module_path, folder)\n",
        "    shutil.copytree(source_folder, destination_folder, dirs_exist_ok=True)\n",
        "    os.remove(\"temp.zip\")\n",
        "    shutil.rmtree(\"temp_dir\")\n",
        "  else:\n",
        "    print(f\"filed to download {zip_url}: {response.status_code}, {response.text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkyAlfNt6BWu",
        "outputId": "54177168-2292-4fd3-ebe8-fa943184d599"
      },
      "outputs": [],
      "source": [
        "if IS_GOOGLE_COLAB:\n",
        "  drive.mount(mount_path)\n",
        "  module_path = f\"{mount_path}/My Drive/modules\"\n",
        "else:\n",
        "  module_path = '../../modules'\n",
        "\n",
        "if os.path.exists(module_path) is False:\n",
        "  os.makedirs(module_path)\n",
        "\n",
        "repositories = [\n",
        "    {'repository': 'stocknet_study', 'branch': 'master', 'folder': 'Dataset', 'refresh': False},\n",
        "    {'repository': 'finance_process', 'branch': 'master', 'folder': 'fprocess', 'refresh': False},\n",
        "    {'repository': 'cloud_storage_handler', 'branch': 'main', 'folder': 'cloud_storage_handler', 'refresh': False},\n",
        "]\n",
        "\n",
        "destination = os.path.join(module_path, '__init__.py')\n",
        "if os.path.exists(destination) is False:\n",
        "  with open(destination, mode='w') as fp:\n",
        "    fp.close()\n",
        "\n",
        "for repo_kwargs in repositories:\n",
        "  destination = os.path.join(module_path, repo_kwargs['folder'])\n",
        "  if repo_kwargs['refresh'] or os.path.exists(destination) is False:\n",
        "    download_modlue_from_gh(**repo_kwargs, module_path=module_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WKc2GcyNLfz4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "f:\\d_drive\\workspace\\stocknet_study\\venv_38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from torch.nn import (TransformerDecoder, TransformerDecoderLayer,\n",
        "                      TransformerEncoder, TransformerEncoderLayer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6UEd9jPlLjKz"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "\n",
        "\n",
        "if IS_GOOGLE_COLAB:\n",
        "    module_path = os.path.abspath(\"/content/drive/My Drive/modules\")\n",
        "    sys.path.append(module_path)\n",
        "    import fprocess\n",
        "else:\n",
        "    module_path = os.path.abspath(\"../..\")\n",
        "    sys.path.append(module_path)\n",
        "    from fprocess import fprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yGgZdgNciWe"
      },
      "source": [
        "## Agent Simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLWxWQQ6cnRb"
      },
      "source": [
        "### Determinisitc Simulation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fu9IDbosc8Cc"
      },
      "outputs": [],
      "source": [
        "from Dataset.generator import AgentSimulationTrainDataGenerator\n",
        "\n",
        "agent_num = 300\n",
        "parallel_model_count = 3\n",
        "agent_config_01 = {\n",
        "    \"spread\":0.1, \"max_volatility\":0.05, \"min_volatility\":0.001, \"initial_positions\": [(-1)**i for i in range(agent_num)]\n",
        "}\n",
        "agent_config_02 = {\n",
        "    \"spread\":0.1, \"max_volatility\":0.05, \"min_volatility\":0.001, \"initial_positions\": [1 if i < int(300*0.6) else -1 for i in range(agent_num)]\n",
        "}\n",
        "agent_config_03 = {\n",
        "    \"spread\":0.1, \"max_volatility\":0.05, \"min_volatility\":0.001, \"initial_positions\": [1 if i < int(300*0.4) else -1 for i in range(agent_num)]\n",
        "}\n",
        "agent_config = [agent_config_01, agent_config_02, agent_config_03]\n",
        "obs_total_seconds = 60 * 30\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1qFgPbagbwAh"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(f\"{data_folder}/OANDA_2021_tick.zip\", parse_dates=True, index_col=0)\n",
        "index = df.index\n",
        "df = df.resample(\"MIN\").ohlc().dropna()\n",
        "df = df.price.diff()\n",
        "stats = df.describe()\n",
        "columns = df.columns\n",
        "del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "beKh5eKl9oZA"
      },
      "outputs": [],
      "source": [
        "min_values = stats.loc[\"min\"]\n",
        "max_values = stats.loc[\"max\"]\n",
        "diff_p = fprocess.DiffPreProcess(columns=[\"open\", \"high\", \"low\", \"close\"])\n",
        "standalization_p = fprocess.MinMaxPreProcess(columns=[\"open\", \"high\", \"low\", \"close\"], min_values=min_values, max_values=max_values)\n",
        "processes = [diff_p, standalization_p]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_generator = AgentSimulationTrainDataGenerator(agent_per_model = 300, output_length=70, model_count=parallel_model_count, sample_timeindex=index, model_config=agent_config,\n",
        "                                                   processes=processes, batch_first=True, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9xxSYHYBPtk"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000, dropout=0.05):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(-2)\n",
        "        #pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_pos = src.size(0)\n",
        "        tgt_pos = src_pos + tgt.size(0) - 1\n",
        "        return self.dropout(src + self.pe[:src_pos, :]), self.dropout(tgt + self.pe[src_pos-1:tgt_pos, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QtDgWQ_BhOS"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqTransformer(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self, num_encoder_layers: int, num_decoder_layers: int,\n",
        "        feature_size: int, batch_first=True,\n",
        "        dim_feedforward:int = 512, dropout:float = 0.1, nhead:int = 8\n",
        "    ):\n",
        "\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "\n",
        "        self.positional_encoding = PositionalEncoding(feature_size, dropout=dropout)\n",
        "\n",
        "        encoder_layer = TransformerEncoderLayer(\n",
        "            d_model=feature_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=batch_first\n",
        "        )\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
        "\n",
        "        decoder_layer = TransformerDecoderLayer(\n",
        "            d_model=feature_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=batch_first\n",
        "        )\n",
        "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
        "\n",
        "    def forward(\n",
        "        self, src: Tensor, tgt: Tensor, mask_tgt: Tensor,\n",
        "        mask_src: Tensor=None, padding_mask_src: Tensor=None, padding_mask_tgt: Tensor=None,\n",
        "        memory_key_padding_mask: Tensor=None\n",
        "    ):\n",
        "\n",
        "        src, tgt = self.positional_encoding(src, tgt)\n",
        "        memory = self.transformer_encoder(src, mask_src, padding_mask_src)\n",
        "        outs = self.transformer_decoder(\n",
        "            tgt, memory, mask_tgt, None,\n",
        "            padding_mask_tgt, memory_key_padding_mask\n",
        "        )\n",
        "        return outs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KegCtpfDBmVq"
      },
      "outputs": [],
      "source": [
        "SMA=100\n",
        "\n",
        "def train(obs_length, model, generator, optimizer, criterion, batch_size, device):\n",
        "\n",
        "    model.train()\n",
        "    losses = np.array([])\n",
        "    sma_loss = np.inf\n",
        "    for observations in generator:\n",
        "\n",
        "        # assume batch_first=True\n",
        "        src = observations[:, :obs_length]\n",
        "        tgt = observations[:, obs_length:]\n",
        "\n",
        "        input_tgt = tgt[:, :-1]\n",
        "\n",
        "        mask_tgt = nn.Transformer.generate_square_subsequent_mask(input_tgt.size(1)).to(device)\n",
        "        logits = model(\n",
        "            src=src, tgt=input_tgt,  mask_tgt=mask_tgt\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output_tgt = tgt[:, 1:]\n",
        "        loss = criterion(logits, output_tgt)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_value = loss.item()\n",
        "        losses = np.append(losses, loss_value)\n",
        "        if len(losses) >= SMA:\n",
        "          if len(losses) % 10 == 0:\n",
        "            mean_loss = losses[-SMA:].mean()\n",
        "            if sma_loss >= mean_loss:\n",
        "              sma_loss = mean_loss\n",
        "            else:\n",
        "              break\n",
        "    return losses.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By31cG3aEf5W"
      },
      "outputs": [],
      "source": [
        "model_version = 1\n",
        "model_name = f\"pretrainiing_ohlc_{data_generator.sampler_rule}_v{model_version}\"\n",
        "\n",
        "nhead = 2\n",
        "dim_feedforward = 1\n",
        "num_encoder_layers = 1\n",
        "num_decoder_layers = 1\n",
        "dropout = 0.1\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = Seq2SeqTransformer(\n",
        "    num_encoder_layers=num_encoder_layers,\n",
        "    num_decoder_layers=num_decoder_layers,\n",
        "    feature_size=4,\n",
        "    dim_feedforward=dim_feedforward,\n",
        "    dropout=dropout, nhead=nhead,\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEG3JTNVEsHB"
      },
      "outputs": [],
      "source": [
        "lr = 0.0005\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma = 0.95)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = f\"{data_folder}/{model_name}.state\"\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    if torch.cuda.is_available():\n",
        "        check_point = torch.load(model_path)\n",
        "    else:\n",
        "        check_point = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "    model.load_state_dict(check_point['model_state_dict'])\n",
        "    optimizer.load_state_dict(check_point['optimizer_state_dict'])\n",
        "    scheduler.load_state_dict(check_point['scheduler_state_dict'])\n",
        "else:\n",
        "    print(\"start training a new model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESAQ5wOVFCNC",
        "outputId": "0de38e59-a094-4584-a980-bc9119645b77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40\n",
            "epoc: 1, loss: 0.0008273472718428821\n",
            "80\n",
            "epoc: 2, loss: 0.0007707675016717985\n",
            "80\n",
            "epoc: 3, loss: 0.0007932903674372938\n",
            "40\n",
            "epoc: 4, loss: 0.0007469542222679592\n",
            "50\n",
            "epoc: 5, loss: 0.0007474757928866893\n",
            "40\n",
            "epoc: 6, loss: 0.0007578721852041781\n",
            "40\n",
            "epoc: 7, loss: 0.0007321291137486696\n",
            "40\n",
            "epoc: 8, loss: 0.0006980493431910873\n",
            "70\n",
            "epoc: 9, loss: 0.0006928286881053022\n",
            "40\n",
            "epoc: 10, loss: 0.0007172456593252718\n",
            "80\n",
            "epoc: 11, loss: 0.0006900915890582837\n",
            "50\n",
            "epoc: 12, loss: 0.0006746361823752522\n",
            "40\n",
            "epoc: 13, loss: 0.0006745217106072232\n",
            "40\n",
            "epoc: 14, loss: 0.0006751551729394123\n",
            "110\n",
            "epoc: 15, loss: 0.0006756118350577625\n",
            "60\n",
            "epoc: 16, loss: 0.0006489181279903278\n",
            "40\n",
            "epoc: 17, loss: 0.0006655260833213106\n",
            "40\n",
            "epoc: 18, loss: 0.0006402997649274766\n",
            "50\n",
            "epoc: 19, loss: 0.0006138340005418286\n",
            "40\n",
            "epoc: 20, loss: 0.0006358670769259333\n",
            "40\n",
            "epoc: 21, loss: 0.0006139543402241543\n",
            "50\n",
            "epoc: 22, loss: 0.0006232692324556411\n",
            "40\n",
            "epoc: 23, loss: 0.0006505652767373249\n"
          ]
        }
      ],
      "source": [
        "epoch = 500\n",
        "best_train_loss = np.inf\n",
        "best_train_model = None\n",
        "patience = 3\n",
        "counter = 0\n",
        "\n",
        "for loop in range(1, epoch + 1):\n",
        "  loss_train = train(\n",
        "      obs_length=60,\n",
        "      model=model, generator=data_generator, optimizer=optimizer,\n",
        "      criterion=criterion, batch_size=batch_size,\n",
        "      device=device\n",
        "  )\n",
        "\n",
        "  if best_train_loss > loss_train:\n",
        "    best_train_loss = loss_train\n",
        "    best_train_model = model\n",
        "    counter = 0\n",
        "  else:\n",
        "    counter += 1\n",
        "    scheduler.step()\n",
        "  print(f\"epoc: {loop}, loss: {loss_train}\")\n",
        "\n",
        "  if counter > patience:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnq8Fn8Mh0QH"
      },
      "outputs": [],
      "source": [
        "torch.save({\n",
        "  'model_state_dict': best_train_model.state_dict(),\n",
        "  'optimizer_state_dict': optimizer.state_dict(),\n",
        "  'scheduler_state_dict': scheduler.state_dict(),\n",
        "}, f\"{data_folder}/{model_name}.state\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "os.makedirs(f\"{data_folder}/simulations\", exist_ok=True)\n",
        "\n",
        "date_str = datetime.datetime.now().isoformat()\n",
        "for index, data in enumerate(data_generator.row_data):\n",
        "    sim_srs = pd.Series(data, index=data_generator.sample_timemindex[:len(data)])\n",
        "    sim_srs.to_csv(f\"{data_folder}/simulations/{date_str}_{index}.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
