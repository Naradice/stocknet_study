{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKwKaQIdQyBg"
      },
      "source": [
        "Approraches\n",
        "\n",
        "1. Training a model with simulation results\n",
        "1. Training a model with another symbols\n",
        "1. Training a model with pertubation\n",
        "1. Training a model with output of statistic model\n",
        "1. Training a model with weight average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "e8LWcYfjBBO6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  IS_GOOGLE_COLAB = True\n",
        "except ImportError:\n",
        "  IS_GOOGLE_COLAB = False\n",
        "\n",
        "if IS_GOOGLE_COLAB:\n",
        "  mount_path = '/content/drive'\n",
        "  base_folder = os.path.join(mount_path, \"My Drive\", \"Data\")\n",
        "  data_folder = os.path.join(base_folder, \"FX\")\n",
        "else:\n",
        "  base_folder = '../../../Data'\n",
        "  data_folder = os.path.join(base_folder, \"FX\", \"OANDA-Japan MT5 Live\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nXPzChzz8XIq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import requests\n",
        "\n",
        "def download_modlue_from_gh(repository, github_account='Naradice', branch='master', folder=None, module_path='/gdrive/My Drive/modules', **kwargs):\n",
        "  if folder is None:\n",
        "    folder = repository\n",
        "\n",
        "  zip_url = f\"https://github.com/{github_account}/{repository}/archive/refs/heads/{branch}.zip\"\n",
        "  response = requests.get(zip_url)\n",
        "  if response.status_code == 200:\n",
        "    with open(\"temp.zip\", \"wb\") as f:\n",
        "      f.write(response.content)\n",
        "    with zipfile.ZipFile(\"temp.zip\", \"r\") as zip_ref:\n",
        "      zip_ref.extractall(\"temp_dir\")\n",
        "\n",
        "    source_folder = f\"temp_dir/{repository}-{branch}/{folder}\"\n",
        "    destination_folder = os.path.join(module_path, folder)\n",
        "    shutil.copytree(source_folder, destination_folder, dirs_exist_ok=True)\n",
        "    os.remove(\"temp.zip\")\n",
        "    shutil.rmtree(\"temp_dir\")\n",
        "  else:\n",
        "    print(f\"filed to download {zip_url}: {response.status_code}, {response.text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkyAlfNt6BWu",
        "outputId": "54177168-2292-4fd3-ebe8-fa943184d599"
      },
      "outputs": [],
      "source": [
        "if IS_GOOGLE_COLAB:\n",
        "  drive.mount(mount_path)\n",
        "  module_path = f\"{mount_path}/My Drive/modules\"\n",
        "else:\n",
        "  module_path = '../../modules'\n",
        "\n",
        "if os.path.exists(module_path) is False:\n",
        "  os.makedirs(module_path)\n",
        "\n",
        "repositories = [\n",
        "    {'repository': 'stocknet_study', 'branch': 'master', 'folder': 'Dataset', 'refresh': False},\n",
        "    {'repository': 'finance_process', 'branch': 'master', 'folder': 'fprocess', 'refresh': False},\n",
        "    {'repository': 'cloud_storage_handler', 'branch': 'main', 'folder': 'cloud_storage_handler', 'refresh': False},\n",
        "]\n",
        "\n",
        "destination = os.path.join(module_path, '__init__.py')\n",
        "if os.path.exists(destination) is False:\n",
        "  with open(destination, mode='w') as fp:\n",
        "    fp.close()\n",
        "\n",
        "for repo_kwargs in repositories:\n",
        "  destination = os.path.join(module_path, repo_kwargs['folder'])\n",
        "  if repo_kwargs['refresh'] or os.path.exists(destination) is False:\n",
        "    download_modlue_from_gh(**repo_kwargs, module_path=module_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WKc2GcyNLfz4"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from torch.nn import (TransformerDecoder, TransformerDecoderLayer,\n",
        "                      TransformerEncoder, TransformerEncoderLayer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6UEd9jPlLjKz"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "\n",
        "sys.path.append(module_path)\n",
        "try:\n",
        "    from fprocess import fprocess\n",
        "except ImportError:\n",
        "    import fprocess\n",
        "    \n",
        "from Dataset import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize cloud storage handler if needed\n",
        "from cloud_storage_handler import DropboxHandler\n",
        "\n",
        "\n",
        "# storage_handler = DropboxHandler(\"nhjrq1cjpugk5hc\", \"http://localhost\")\n",
        "# storage_handler.authenticate()\n",
        "# Otherwise, specify None\n",
        "storage_handler = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yGgZdgNciWe"
      },
      "source": [
        "## Agent Simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLWxWQQ6cnRb"
      },
      "source": [
        "### Determinisitc Simulation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fu9IDbosc8Cc"
      },
      "outputs": [],
      "source": [
        "from Dataset.generator import AgentSimulationTrainDataGenerator\n",
        "\n",
        "agent_num = 300\n",
        "parallel_model_count = 3\n",
        "agent_config_01 = {\n",
        "    \"spread\":0.1, \"max_volatility\":0.05, \"min_volatility\":0.001, \"initial_positions\": [(-1)**i for i in range(agent_num)]\n",
        "}\n",
        "agent_config_02 = {\n",
        "    \"spread\":0.1, \"max_volatility\":0.05, \"min_volatility\":0.001, \"initial_positions\": [1 if i < int(300*0.6) else -1 for i in range(agent_num)]\n",
        "}\n",
        "agent_config_03 = {\n",
        "    \"spread\":0.1, \"max_volatility\":0.05, \"min_volatility\":0.001, \"initial_positions\": [1 if i < int(300*0.4) else -1 for i in range(agent_num)]\n",
        "}\n",
        "agent_config = [agent_config_01, agent_config_02, agent_config_03]\n",
        "observation_length = 60\n",
        "prediction_length = 10\n",
        "total_length = observation_length + prediction_length\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1qFgPbagbwAh"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(f\"{data_folder}/OANDA_2021_tick.zip\", parse_dates=True, index_col=0)\n",
        "index = df.index\n",
        "df = df.resample(\"MIN\").ohlc().dropna()\n",
        "df = df.price.diff()\n",
        "stats = df.describe()\n",
        "columns = list(df.columns)\n",
        "del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "beKh5eKl9oZA"
      },
      "outputs": [],
      "source": [
        "min_values = stats.loc[\"min\"]\n",
        "max_values = stats.loc[\"max\"]\n",
        "diff_p = fprocess.DiffPreProcess(columns=columns)\n",
        "standalization_p = fprocess.MinMaxPreProcess(columns=columns, min_values=min_values, max_values=max_values)\n",
        "processes = [diff_p, standalization_p]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_generator = AgentSimulationTrainDataGenerator(agent_per_model = agent_num, output_length=total_length, model_count=parallel_model_count, sample_timeindex=index, model_config=agent_config,\n",
        "                                                   processes=processes, batch_first=True, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add data previously generated. Remove this code if previouse data shouldn't affect to the training.\n",
        "import glob\n",
        "\n",
        "files = glob.glob(f\"{data_folder}/simulations/*.csv\")\n",
        "tick_data_list = []\n",
        "threathold = 1/10\n",
        "\n",
        "for file in files:\n",
        "    tick_srs = pd.read_csv(file, index_col=0, parse_dates=True)[\"0\"]\n",
        "    if len(tick_srs) > len(index) * threathold:\n",
        "        tick_data_list.append(tick_srs)\n",
        "if len(tick_data_list) > 0:\n",
        "    print(f\"load {len(tick_data_list)} data\")\n",
        "    data_generator.add_multiple_data(tick_data_list)\n",
        "del tick_data_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "m9xxSYHYBPtk"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000, dropout=0.05, batch_first=True):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(-2)\n",
        "        if batch_first:\n",
        "            pe = pe.transpose(0, 1)\n",
        "            self.forward = self.__fforward\n",
        "        else:\n",
        "            self.forward = self.__mforward\n",
        "            \n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def __mforward(self, src, tgt):\n",
        "        src_pos = src.size(0)\n",
        "        tgt_pos = src_pos + tgt.size(0) - 1\n",
        "        return self.dropout(src + self.pe[:src_pos, :]), self.dropout(tgt + self.pe[src_pos-1:tgt_pos, :])\n",
        "    \n",
        "    def __fforward(self, src, tgt):\n",
        "        src_pos = src.size(1)\n",
        "        tgt_pos = src_pos + tgt.size(1) - 1\n",
        "        return self.dropout(src + self.pe[:, :src_pos, :]), self.dropout(tgt + self.pe[:, src_pos-1:tgt_pos, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "2QtDgWQ_BhOS"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqTransformer(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self, num_encoder_layers: int, num_decoder_layers: int,\n",
        "        feature_size: int, batch_first=True,\n",
        "        dim_feedforward:int = 512, dropout:float = 0.1, nhead:int = 8\n",
        "    ):\n",
        "\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "\n",
        "        self.positional_encoding = PositionalEncoding(feature_size, dropout=dropout, batch_first=batch_first)\n",
        "\n",
        "        encoder_layer = TransformerEncoderLayer(\n",
        "            d_model=feature_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=batch_first\n",
        "        )\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
        "\n",
        "        decoder_layer = TransformerDecoderLayer(\n",
        "            d_model=feature_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=batch_first\n",
        "        )\n",
        "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
        "\n",
        "    def forward(\n",
        "        self, src: Tensor, tgt: Tensor, mask_tgt: Tensor,\n",
        "        mask_src: Tensor=None, padding_mask_src: Tensor=None, padding_mask_tgt: Tensor=None,\n",
        "        memory_key_padding_mask: Tensor=None\n",
        "    ):\n",
        "\n",
        "        src, tgt = self.positional_encoding(src, tgt)\n",
        "        memory = self.transformer_encoder(src, mask_src, padding_mask_src)\n",
        "        outs = self.transformer_decoder(\n",
        "            tgt, memory, mask_tgt, None,\n",
        "            padding_mask_tgt, memory_key_padding_mask\n",
        "        )\n",
        "        return outs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KegCtpfDBmVq"
      },
      "outputs": [],
      "source": [
        "SMA=100\n",
        "\n",
        "def train(obs_length, model, generator, optimizer, criterion, device, logger=None):\n",
        "\n",
        "    model.train()\n",
        "    losses = np.array([])\n",
        "    sma_loss = np.inf\n",
        "    for observations in generator:\n",
        "\n",
        "        # assume batch_first=True\n",
        "        src = observations[:, :obs_length]\n",
        "        tgt = observations[:, obs_length:]\n",
        "\n",
        "        input_tgt = tgt[:, :-1]\n",
        "\n",
        "        mask_tgt = nn.Transformer.generate_square_subsequent_mask(input_tgt.size(1)).to(device)\n",
        "        logits = model(\n",
        "            src=src, tgt=input_tgt,  mask_tgt=mask_tgt\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output_tgt = tgt[:, 1:]\n",
        "        loss = criterion(logits, output_tgt)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_value = loss.item()\n",
        "        losses = np.append(losses, loss_value)\n",
        "        if len(losses) >= SMA:\n",
        "          if len(losses) % 10 == 0:\n",
        "            mean_loss = losses[-SMA:].mean()\n",
        "            if logger is not None:\n",
        "              logger.add_training_log(mean_loss, 0)\n",
        "            if sma_loss >= mean_loss:\n",
        "              sma_loss = mean_loss\n",
        "            else:\n",
        "              break\n",
        "    return losses.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model(num_encoder_layers, num_decoder_layers, feature_size, dim_feedforward, dropout, nhead, **kwargs):\n",
        "    model = Seq2SeqTransformer(\n",
        "        num_encoder_layers=num_encoder_layers,\n",
        "        num_decoder_layers=num_decoder_layers,\n",
        "        feature_size=feature_size,\n",
        "        dim_feedforward=dim_feedforward,\n",
        "        dropout=dropout, nhead=nhead,\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "exsisting model not found.\n",
            "Initialize a new model.\n",
            "params: 306\n"
          ]
        }
      ],
      "source": [
        "model_version = 1\n",
        "model_name = f\"pretrainiing_ohlc_{data_generator.sampler_rule}\"\n",
        "# Hyper parameters. If model name and version is already used, load it from params file instead.\n",
        "nhead = 2\n",
        "dim_feedforward = 1\n",
        "num_encoder_layers = 1\n",
        "num_decoder_layers = 1\n",
        "dropout = 0.1\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer_class=torch.optim.Adam\n",
        "lr = 0.005\n",
        "scheduler_class=torch.optim.lr_scheduler.StepLR\n",
        "gamma = 0.95\n",
        "device = utils.get_device()\n",
        "logger = utils.Logger(model_name, model_version, base_folder, storage_handler=storage_handler)\n",
        "\n",
        "success, model_params, model, optimizer, scheduler, best_train_loss = logger.load_model_checkpoint(create_model, model_name, model_version, \n",
        "                                                                        train=True, storage_handler=storage_handler,\n",
        "                                                                        optimizer_class=optimizer_class,\n",
        "                                                                        scheduler_class=scheduler_class)\n",
        "\n",
        "if success is False:\n",
        "    print(\"Initialize a new model.\")\n",
        "    if model_params is None:\n",
        "        model_params = {\n",
        "            \"nhead\": nhead,\n",
        "            \"dim_feedforward\": dim_feedforward,\n",
        "            \"num_encoder_layers\": num_encoder_layers,\n",
        "            \"num_decoder_layers\": num_decoder_layers,\n",
        "            \"dropout\": dropout,\n",
        "            \"feature_size\": 4\n",
        "        }\n",
        "    if model is None:\n",
        "        model = create_model(\n",
        "            **model_params\n",
        "        ).to(device)\n",
        "        optimizer = optimizer_class(model.parameters(), lr=lr)\n",
        "        scheduler = scheduler_class(optimizer, step_size=1, gamma=gamma)\n",
        "\n",
        "params_num = 0\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "    if p.requires_grad:\n",
        "        params_num += p.numel()\n",
        "print(f\"params: {params_num}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training log will be saved on  ../../../Data\\pretrainiing_ohlc_MIN\\pretrainiing_ohlc_MIN_v1.csv\n"
          ]
        }
      ],
      "source": [
        "params = {\"processes\": fprocess.preprocess_to_params(processes),\n",
        "          \"source\": {\n",
        "              \"type\": \"simulation\",\n",
        "              \"agent_num\": agent_num,\n",
        "              \"agent_config\": agent_config,\n",
        "          },\n",
        "          \"feature_size\": len(columns),\n",
        "          \"features\": columns,\n",
        "          \"batch_size\": batch_size,\n",
        "          \"observation_length\": observation_length,\n",
        "          \"prediction_length\": prediction_length,\n",
        "          **model_params,\n",
        "          \"params_num\": params_num,\n",
        "          \"version\": 2\n",
        "}\n",
        "\n",
        "logger.save_params(params, model_name, model_version)\n",
        "\n",
        "print(\"training log will be saved on \", logger.log_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESAQ5wOVFCNC",
        "outputId": "0de38e59-a094-4584-a980-bc9119645b77"
      },
      "outputs": [],
      "source": [
        "epoch = 500\n",
        "best_train_loss = np.inf\n",
        "best_train_model = None\n",
        "patience = 3\n",
        "counter = 0\n",
        "\n",
        "for loop in range(1, epoch + 1):\n",
        "  loss_train = train(\n",
        "      obs_length=observation_length,\n",
        "      model=model, generator=data_generator, optimizer=optimizer,\n",
        "      criterion=criterion, device=device, logger=logger\n",
        "  )\n",
        "\n",
        "  if best_train_loss > loss_train:\n",
        "    best_train_loss = loss_train\n",
        "    best_train_model = model\n",
        "    counter = 0\n",
        "  else:\n",
        "    counter += 1\n",
        "    scheduler.step()\n",
        "  print(f\"epoc: {loop}, loss: {loss_train}\")\n",
        "  logger.add_training_log(loss_train, 0.0)\n",
        "\n",
        "  if counter > patience:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "logger.save_checkpoint(best_train_model, optimizer, scheduler, model_name, model_version, best_train_loss)\n",
        "data_generator.save_ticks(f\"{data_folder}/simulations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if IS_GOOGLE_COLAB:\n",
        "    # run this method if you want to disconnect runtime after the traning ends\n",
        "    from google.colab import runtime\n",
        "\n",
        "    drive.flush_and_unmount()\n",
        "    runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
