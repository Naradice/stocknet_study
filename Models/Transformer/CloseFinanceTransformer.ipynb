{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another BaseLine Transformer model\n",
    "\n",
    "Caution: This is not a usual use case of Transformer.\n",
    "\n",
    "Transformer developed by Google usually use Embeddeding Layer to represents a target such as a word.\n",
    "\n",
    "In this model, I use Close values as a state vector though we can take same approch for finance data.\n",
    "As feature is very limited, this would be a base line of Transformer.\n",
    "\n",
    "Parameters:\n",
    "- Input:  ohlc_df[\"close\"].iloc[index: index+data_length] while observation_length\n",
    "- Target: ohlc_df[\"close\"].iloc[index + observation_length:index + observation_length + data_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ohlc_column = ('open','high','low','close')\n",
    "file_path = os.path.abspath('mt5_USDJPY_min30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>tick_volume</th>\n",
       "      <th>spread</th>\n",
       "      <th>real_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-07-07 08:30:00</th>\n",
       "      <td>102.086</td>\n",
       "      <td>102.122</td>\n",
       "      <td>102.081</td>\n",
       "      <td>102.102</td>\n",
       "      <td>738</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-07 09:00:00</th>\n",
       "      <td>102.102</td>\n",
       "      <td>102.146</td>\n",
       "      <td>102.098</td>\n",
       "      <td>102.113</td>\n",
       "      <td>1036</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-07 09:30:00</th>\n",
       "      <td>102.113</td>\n",
       "      <td>102.115</td>\n",
       "      <td>102.042</td>\n",
       "      <td>102.044</td>\n",
       "      <td>865</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-07 10:00:00</th>\n",
       "      <td>102.047</td>\n",
       "      <td>102.052</td>\n",
       "      <td>102.005</td>\n",
       "      <td>102.019</td>\n",
       "      <td>983</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-07 10:30:00</th>\n",
       "      <td>102.017</td>\n",
       "      <td>102.025</td>\n",
       "      <td>101.918</td>\n",
       "      <td>101.941</td>\n",
       "      <td>1328</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-12 21:30:00</th>\n",
       "      <td>133.461</td>\n",
       "      <td>133.506</td>\n",
       "      <td>133.439</td>\n",
       "      <td>133.484</td>\n",
       "      <td>1125</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-12 22:00:00</th>\n",
       "      <td>133.484</td>\n",
       "      <td>133.530</td>\n",
       "      <td>133.437</td>\n",
       "      <td>133.475</td>\n",
       "      <td>1277</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-12 22:30:00</th>\n",
       "      <td>133.475</td>\n",
       "      <td>133.486</td>\n",
       "      <td>133.433</td>\n",
       "      <td>133.483</td>\n",
       "      <td>1506</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-12 23:00:00</th>\n",
       "      <td>133.484</td>\n",
       "      <td>133.536</td>\n",
       "      <td>133.465</td>\n",
       "      <td>133.521</td>\n",
       "      <td>1038</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-12 23:30:00</th>\n",
       "      <td>133.521</td>\n",
       "      <td>133.522</td>\n",
       "      <td>133.301</td>\n",
       "      <td>133.313</td>\n",
       "      <td>2515</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100720 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open     high      low    close  tick_volume  spread  \\\n",
       "time                                                                           \n",
       "2014-07-07 08:30:00  102.086  102.122  102.081  102.102          738       3   \n",
       "2014-07-07 09:00:00  102.102  102.146  102.098  102.113         1036       3   \n",
       "2014-07-07 09:30:00  102.113  102.115  102.042  102.044          865       3   \n",
       "2014-07-07 10:00:00  102.047  102.052  102.005  102.019          983       3   \n",
       "2014-07-07 10:30:00  102.017  102.025  101.918  101.941         1328       3   \n",
       "...                      ...      ...      ...      ...          ...     ...   \n",
       "2022-08-12 21:30:00  133.461  133.506  133.439  133.484         1125       3   \n",
       "2022-08-12 22:00:00  133.484  133.530  133.437  133.475         1277       3   \n",
       "2022-08-12 22:30:00  133.475  133.486  133.433  133.483         1506       3   \n",
       "2022-08-12 23:00:00  133.484  133.536  133.465  133.521         1038       3   \n",
       "2022-08-12 23:30:00  133.521  133.522  133.301  133.313         2515       3   \n",
       "\n",
       "                     real_volume  \n",
       "time                              \n",
       "2014-07-07 08:30:00            0  \n",
       "2014-07-07 09:00:00            0  \n",
       "2014-07-07 09:30:00            0  \n",
       "2014-07-07 10:00:00            0  \n",
       "2014-07-07 10:30:00            0  \n",
       "...                          ...  \n",
       "2022-08-12 21:30:00            0  \n",
       "2022-08-12 22:00:00            0  \n",
       "2022-08-12 22:30:00            0  \n",
       "2022-08-12 23:00:00            0  \n",
       "2022-08-12 23:30:00            0  \n",
       "\n",
       "[100720 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn import (TransformerDecoder, TransformerDecoderLayer,\n",
    "                      TransformerEncoder, TransformerEncoderLayer)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class CloseDataset:    \n",
    "    key = \"close\"\n",
    "\n",
    "    def __init__(self, df, close_column=\"close\", date_column=\"index\", data_length=30, observation_length:int=31,\n",
    "                 device=\"cuda\", init_type=\"log\", future_step_size=10, seed=1192, is_training = True):\n",
    "        self.seed(seed)\n",
    "        \n",
    "        close_df = df[[close_column]]\n",
    "        close_df = close_df.apply(np.log).diff()\n",
    "        if init_type == \"cumsum\":\n",
    "            close_df = close_df.cumsum()\n",
    "        scale = (-1, 1)\n",
    "        min_series = close_df.min()\n",
    "        max_series = close_df.max()\n",
    "        std = (close_df - min_series)/(max_series - min_series)\n",
    "        close_df = std * (scale[1] - scale[0]) + scale[0]\n",
    "        \n",
    "        self.__get_timeindex = lambda idx :None\n",
    "        if date_column:\n",
    "            hours_of_week = (df.index.weekday*24 + df.index.hour + df.index.minute/60)*(60/30)\n",
    "            self.hours_of_week = hours_of_week.to_frame().iloc[1:].convert_dtypes(int)\n",
    "            \n",
    "        self.observation_length = observation_length\n",
    "        self.data_length = data_length\n",
    "        self.is_training = is_training\n",
    "        self.device = device\n",
    "        self._data = close_df\n",
    "        self._columns = close_column\n",
    "        self._future_step_size = future_step_size\n",
    "        self._init_indicies(close_df)\n",
    "    \n",
    "    def __get_timeindex(self, index, length):\n",
    "        indices = [index+ bias+ self.data_length for bias in range(length)]\n",
    "        return self.hours_of_week.iloc[indices].values.tolist()\n",
    "                \n",
    "    def _outputFunc(self, batch_size):\n",
    "        if type(batch_size) == int:\n",
    "            pass\n",
    "        elif type(batch_size) == slice:\n",
    "            batch_indices = batch_size                \n",
    "            chunk_tgt = []\n",
    "            time_chunk_tgt = []\n",
    "            ndx = self._indices[batch_indices]\n",
    "            \n",
    "            for index in ndx:\n",
    "                future_tgt = []\n",
    "                future_time = []\n",
    "                # -1 for shift\n",
    "                for bias in range(-1, self._future_step_size):\n",
    "                    start_index = index + self.observation_length - self.data_length  + bias\n",
    "                    stop_index = index + self.observation_length + bias\n",
    "                    step_ndx = slice(start_index, stop_index)\n",
    "                    future_tgt.append(self._data[self._columns][step_ndx].values.tolist())\n",
    "                    future_time.append(self.hours_of_week.iloc[stop_index].values.tolist())\n",
    "                chunk_tgt.append(future_tgt)\n",
    "                time_chunk_tgt.append(future_time)\n",
    "            \n",
    "            return torch.tensor(chunk_tgt, device=self.device, dtype=torch.float).transpose(0, 1), torch.tensor(time_chunk_tgt, device=self.device).transpose(0, 1)\n",
    "    \n",
    "    def _inputFunc(self, batch_size):\n",
    "        if type(batch_size) == int:\n",
    "            pass\n",
    "        elif type(batch_size) == slice:\n",
    "            batch_indices = batch_size\n",
    "            chunk_src = []\n",
    "            time_chunk_src = []\n",
    "            ndx = self._indices[batch_indices]\n",
    "            \n",
    "            for index in ndx:\n",
    "                obs_src = []\n",
    "                obs_time = []\n",
    "                for bias in range(self.observation_length):\n",
    "                    stop_index = index + bias\n",
    "                    obs_ndx = slice(index - self.data_length + bias, stop_index)\n",
    "                    obs_src.append(self._data[self._columns][obs_ndx].values.tolist())\n",
    "                    obs_time.append(self.hours_of_week.iloc[stop_index].values.tolist())\n",
    "                chunk_src.append(obs_src)\n",
    "                time_chunk_src.append(obs_time)\n",
    "        \n",
    "            return torch.tensor(chunk_src, device=self.device, dtype=torch.float).transpose(0, 1), torch.tensor(time_chunk_src, device=self.device).transpose(0, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._indices)\n",
    "    \n",
    "    def __getitem__(self, ndx):\n",
    "        return self._inputFunc(ndx), self._outputFunc(ndx)\n",
    "           \n",
    "    def seed(self, seed=None):\n",
    "        '''\n",
    "        '''\n",
    "        if seed == None:\n",
    "            seed = 1192\n",
    "        else:\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        self.seed_value = seed\n",
    "        \n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "        \n",
    "    def render(self, mode='human', close=False):\n",
    "        '''\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def get_actual_index(self,ndx):\n",
    "        inputs = []\n",
    "        if type(ndx) == slice:\n",
    "            for index in self._indices[ndx]:\n",
    "                inputs.append(index)\n",
    "        else:\n",
    "            inputs = self._indices[ndx]\n",
    "        return inputs\n",
    "    \n",
    "    def get_row_data(self, ndx):\n",
    "        inputs = []\n",
    "        if type(ndx) == slice:\n",
    "            for index in self._indices[ndx]:\n",
    "                df = self._data[index: index + self.observation_length]\n",
    "                inputs.append(df)\n",
    "        else:\n",
    "            index = ndx\n",
    "            inputs = df = self._data[index: index + self.observation_length]\n",
    "        return inputs\n",
    "\n",
    "    def _init_indicies(self, data, split_ratio=0.7):\n",
    "        length = len(data) - self.observation_length -self.data_length - self._future_step_size\n",
    "        if length < 0:\n",
    "            raise Exception(f\"date length {length} is less than observation_length {self.observation_length}\")\n",
    "        \n",
    "        from_index = self.data_length + 1#avoid diff nan\n",
    "        to_index = int(length*split_ratio)\n",
    "        self.train_indices = random.sample(range(from_index, to_index), k=to_index - from_index)\n",
    "        \n",
    "        from_index = int(length*split_ratio) + self.observation_length + self.data_length + self._future_step_size\n",
    "        to_index = length\n",
    "        self.val_indices = random.sample(range(from_index, to_index), k=to_index - from_index)\n",
    "        \n",
    "        if self.is_training:\n",
    "            self._indices = self.train_indices\n",
    "        else:\n",
    "            self._indices = self.val_indices\n",
    "            \n",
    "    def eval(self):\n",
    "        self._indices = self.val_indices\n",
    "        self.is_training = False\n",
    "        \n",
    "    def train(self):\n",
    "        self._indices = self.train_indices\n",
    "        self.is_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = CloseDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, tgt = ds[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([31, 16, 30]), torch.Size([31, 16, 1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src[0].shape, src[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11, 16, 30]), torch.Size([11, 16, 1]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt[0].shape, tgt[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70423\n",
      "torch.Size([31, 16, 30]) torch.Size([31, 16, 1])\n",
      "torch.Size([11, 16, 30]) torch.Size([11, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "ds.train()\n",
    "print(len(ds))\n",
    "\n",
    "for index in range(0, len(ds)-16, 16):\n",
    "    src, tgt = ds[index: index+16]\n",
    "    \n",
    "print(src[0].shape, src[1].shape)\n",
    "print(tgt[0].shape, tgt[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30124\n",
      "torch.Size([31, 16, 30]) torch.Size([31, 16, 1])\n",
      "torch.Size([11, 16, 30]) torch.Size([11, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "ds.eval()\n",
    "print(len(ds))\n",
    "\n",
    "for index in range(0, len(ds)-16, 16):\n",
    "    src, tgt = ds[index: index+16]\n",
    "    \n",
    "print(src[0].shape, src[1].shape)\n",
    "print(tgt[0].shape, tgt[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2735, 0.2639, 0.2650, 0.2623, 0.2666, 0.2703, 0.2655, 0.2719, 0.2496,\n",
       "        0.2687, 0.2629, 0.2767, 0.2655, 0.2698, 0.2618, 0.2517, 0.2597, 0.2533,\n",
       "        0.2857, 0.2719, 0.2341, 0.2942, 0.2724, 0.2698, 0.2730, 0.2543, 0.2862,\n",
       "        0.3032, 0.2793, 0.2618], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src[0][-1, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2735, 0.2639, 0.2650, 0.2623, 0.2666, 0.2703, 0.2655, 0.2719, 0.2496,\n",
       "        0.2687, 0.2629, 0.2767, 0.2655, 0.2698, 0.2618, 0.2517, 0.2597, 0.2533,\n",
       "        0.2857, 0.2719, 0.2341, 0.2942, 0.2724, 0.2698, 0.2730, 0.2543, 0.2862,\n",
       "        0.3032, 0.2793, 0.2618], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt[0][0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalDropout(nn.Dropout):\n",
    "    def forward(self, input):\n",
    "        if self.training:\n",
    "            mask = self.get_mask(input)\n",
    "            return input * mask\n",
    "        else:\n",
    "            return input\n",
    "\n",
    "    def get_mask(self, input):\n",
    "        return torch.ones_like(input).bernoulli_(1 - self.p) / (1 - self.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimePositionalEncoding(nn.Module):\n",
    "    def __init__(self, time_size, d_model, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.pe = nn.Embedding(time_size, d_model, device=device)\n",
    "\n",
    "    def forward(self,time_ids):\n",
    "        position = self.pe(time_ids)\n",
    "        #tetative approach to fix shape\n",
    "        position = position.squeeze(2)\n",
    "        return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, num_encoder_layers: int, num_decoder_layers: int, \n",
    "        feature_size: int=1, time_size: int=48*7, d_model=30,\n",
    "        dim_feedforward:int = 512, dropout:float = 0.1, nhead:int = 8,\n",
    "    ):\n",
    "        \n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        \n",
    "        self.positional_encoding = TimePositionalEncoding(time_size, d_model)\n",
    "        # self.src_dropaut_layer = VariationalDropout(dropout)\n",
    "        # self.tgt_dropaut_layer = VariationalDropout(dropout)\n",
    "        self.src_dropaut_layer = nn.Dropout(dropout)\n",
    "        self.tgt_dropaut_layer = nn.Dropout(dropout)\n",
    "        \n",
    "        encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward\n",
    "        )\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        \n",
    "        decoder_layer = TransformerDecoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward\n",
    "        )\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
    "        \n",
    "        self.output = nn.Linear(d_model, feature_size)\n",
    "\n",
    "    def forward(\n",
    "        self, src: Tensor, src_time, tgt: Tensor, tgt_time,\n",
    "        mask_tgt: Tensor, mask_src: Tensor=None, padding_mask_src: Tensor=None, padding_mask_tgt: Tensor=None,\n",
    "        memory_key_padding_mask: Tensor=None\n",
    "    ):\n",
    "        \n",
    "        src_time = self.positional_encoding(src_time)\n",
    "        src = self.src_dropaut_layer(torch.add(src, src_time))\n",
    "        \n",
    "        tgt_time = self.positional_encoding(tgt_time)\n",
    "        tgt = self.tgt_dropaut_layer(torch.add(tgt, tgt_time))\n",
    "        \n",
    "        memory = self.transformer_encoder(src, mask_src, padding_mask_src)\n",
    "        outs = self.transformer_decoder(\n",
    "            tgt, memory, mask_tgt, None,\n",
    "            padding_mask_tgt, memory_key_padding_mask\n",
    "        )\n",
    "        return self.output(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, ds, optimizer, criterion, batch_size):\n",
    "    \n",
    "    model.train()\n",
    "    ds.train()\n",
    "    losses = 0\n",
    "    \n",
    "    length = 0.0\n",
    "    end_index = len(ds) - batch_size\n",
    "    for index in tqdm(range(0, end_index, batch_size)):\n",
    "        length+=1.0\n",
    "        src, tgt = ds[index:index+batch_size]\n",
    "        src, src_time = src\n",
    "        tgt, tgt_time = tgt\n",
    "\n",
    "        input_tgt = tgt[:-1, :]\n",
    "        input_time_tgt = tgt_time[:-1, :]\n",
    "\n",
    "        mask_tgt = nn.Transformer.generate_square_subsequent_mask(input_tgt.size(0)).to(device)\n",
    "        logits = model(\n",
    "            src=src, src_time=src_time, \n",
    "            tgt=input_tgt, tgt_time=input_time_tgt,\n",
    "            mask_tgt=mask_tgt\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_tgt = tgt[1:, :, -1:]\n",
    "        loss = criterion(logits, output_tgt)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        \n",
    "    return losses / length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, ds, criterion, batch_size):\n",
    "    \n",
    "    model.eval()\n",
    "    ds.eval()\n",
    "    losses = 0\n",
    "    length = 0.0\n",
    "    for index in range(0, len(ds) - batch_size, batch_size):\n",
    "        length+=1.0\n",
    "        src, tgt = ds[index:index+batch_size]\n",
    "        src, src_time = src\n",
    "        tgt, tgt_time = tgt\n",
    "\n",
    "        input_tgt = tgt[:-1, :]\n",
    "        input_time_tgt = tgt_time[:-1, :]\n",
    "\n",
    "        mask_tgt = nn.Transformer.generate_square_subsequent_mask(input_tgt.size(0)).to(device)\n",
    "        logits = model(\n",
    "            src=src, src_time=src_time, \n",
    "            tgt=input_tgt, tgt_time=input_time_tgt,\n",
    "            mask_tgt=mask_tgt\n",
    "        )\n",
    "        \n",
    "        output_tgt = tgt[1:, :, -1:]\n",
    "        loss = criterion(logits, output_tgt)\n",
    "        losses += loss.item()\n",
    "        \n",
    "    return losses / length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "standalization = \"log\"\n",
    "batch_size = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "d_model = 30\n",
    "observation_length = 31\n",
    "future_step_size = 10\n",
    "column = \"close\"\n",
    "\n",
    "ds = CloseDataset(df, close_column=column, data_length=d_model, observation_length=observation_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 1\n",
    "d_model=30\n",
    "nhead = 2\n",
    "dim_feedforward = 1000\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dropout = 0.01\n",
    "time_size = int(24*(60/30)*7)\n",
    "\n",
    "model = Seq2SeqTransformer(\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    num_decoder_layers=num_decoder_layers,\n",
    "    feature_size=feature_size,\n",
    "    time_size=time_size,\n",
    "    d_model=d_model,\n",
    "    dim_feedforward=dim_feedforward,\n",
    "    dropout=dropout, nhead=nhead\n",
    ")\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00005\n",
    "\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 903/1100 [12:48<02:45,  1.19it/s]"
     ]
    }
   ],
   "source": [
    "epoch = 500\n",
    "best_loss = float('Inf')\n",
    "best_model = None\n",
    "patience = 5\n",
    "counter = 0\n",
    "\n",
    "for loop in range(1, epoch + 1):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    loss_train = train(\n",
    "        model=model, ds=ds, optimizer=optimizer,\n",
    "        criterion=criterion, batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    loss_valid = evaluate(\n",
    "        model=model, ds=ds, criterion=criterion,batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    print('[{}/{}] train loss: {:.10f}, valid loss: {:.10f}  [{}{:.0f}s] count: {}, {}'.format(\n",
    "        loop, epoch,\n",
    "        loss_train, loss_valid,\n",
    "        str(int(math.floor(elapsed_time / 60))) + 'm' if math.floor(elapsed_time / 60) > 0 else '',\n",
    "        elapsed_time % 60,\n",
    "        counter,\n",
    "        '**' if best_loss > loss_valid else ''\n",
    "    ))\n",
    "    \n",
    "    if best_loss > loss_valid:\n",
    "        best_loss = loss_valid\n",
    "        best_model = model\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        scheduler.step()\n",
    "        \n",
    "    if counter > patience:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b8f0c1964c2d42c360293b97c2bf126adadb09f88ab60c350427a278226bd93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
