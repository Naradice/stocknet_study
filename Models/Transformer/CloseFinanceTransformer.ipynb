{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another BaseLine Transformer model\n",
    "\n",
    "Caution: This is not a usual use case of Transformer.\n",
    "\n",
    "Transformer developed by Google usually use Embeddeding Layer to represents a target such as a word.\n",
    "\n",
    "In this model, I use Close values as a state vector though we can take same approch for finance data.\n",
    "As feature is very limited, this would be a base line of Transformer.\n",
    "\n",
    "Parameters:\n",
    "- Input:  ohlc_df[\"close\"].iloc[index: index+data_length] while observation_length\n",
    "- Target: ohlc_df[\"close\"].iloc[index + observation_length:index + observation_length + data_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ohlc_column = ('open','high','low','close')\n",
    "file_path = os.path.abspath('../Data/mt5_USDJPY_min30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>tick_volume</th>\n",
       "      <th>spread</th>\n",
       "      <th>real_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-07 08:30:00</td>\n",
       "      <td>102.086</td>\n",
       "      <td>102.122</td>\n",
       "      <td>102.081</td>\n",
       "      <td>102.102</td>\n",
       "      <td>738</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-07 09:00:00</td>\n",
       "      <td>102.102</td>\n",
       "      <td>102.146</td>\n",
       "      <td>102.098</td>\n",
       "      <td>102.113</td>\n",
       "      <td>1036</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-07 09:30:00</td>\n",
       "      <td>102.113</td>\n",
       "      <td>102.115</td>\n",
       "      <td>102.042</td>\n",
       "      <td>102.044</td>\n",
       "      <td>865</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-07 10:00:00</td>\n",
       "      <td>102.047</td>\n",
       "      <td>102.052</td>\n",
       "      <td>102.005</td>\n",
       "      <td>102.019</td>\n",
       "      <td>983</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-07-07 10:30:00</td>\n",
       "      <td>102.017</td>\n",
       "      <td>102.025</td>\n",
       "      <td>101.918</td>\n",
       "      <td>101.941</td>\n",
       "      <td>1328</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100715</th>\n",
       "      <td>2022-08-12 21:30:00</td>\n",
       "      <td>133.461</td>\n",
       "      <td>133.506</td>\n",
       "      <td>133.439</td>\n",
       "      <td>133.484</td>\n",
       "      <td>1125</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100716</th>\n",
       "      <td>2022-08-12 22:00:00</td>\n",
       "      <td>133.484</td>\n",
       "      <td>133.530</td>\n",
       "      <td>133.437</td>\n",
       "      <td>133.475</td>\n",
       "      <td>1277</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100717</th>\n",
       "      <td>2022-08-12 22:30:00</td>\n",
       "      <td>133.475</td>\n",
       "      <td>133.486</td>\n",
       "      <td>133.433</td>\n",
       "      <td>133.483</td>\n",
       "      <td>1506</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100718</th>\n",
       "      <td>2022-08-12 23:00:00</td>\n",
       "      <td>133.484</td>\n",
       "      <td>133.536</td>\n",
       "      <td>133.465</td>\n",
       "      <td>133.521</td>\n",
       "      <td>1038</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100719</th>\n",
       "      <td>2022-08-12 23:30:00</td>\n",
       "      <td>133.521</td>\n",
       "      <td>133.522</td>\n",
       "      <td>133.301</td>\n",
       "      <td>133.313</td>\n",
       "      <td>2515</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100720 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time     open     high  ...  tick_volume  spread  real_volume\n",
       "0       2014-07-07 08:30:00  102.086  102.122  ...          738       3            0\n",
       "1       2014-07-07 09:00:00  102.102  102.146  ...         1036       3            0\n",
       "2       2014-07-07 09:30:00  102.113  102.115  ...          865       3            0\n",
       "3       2014-07-07 10:00:00  102.047  102.052  ...          983       3            0\n",
       "4       2014-07-07 10:30:00  102.017  102.025  ...         1328       3            0\n",
       "...                     ...      ...      ...  ...          ...     ...          ...\n",
       "100715  2022-08-12 21:30:00  133.461  133.506  ...         1125       3            0\n",
       "100716  2022-08-12 22:00:00  133.484  133.530  ...         1277       3            0\n",
       "100717  2022-08-12 22:30:00  133.475  133.486  ...         1506       3            0\n",
       "100718  2022-08-12 23:00:00  133.484  133.536  ...         1038       3            0\n",
       "100719  2022-08-12 23:30:00  133.521  133.522  ...         2515       3            0\n",
       "\n",
       "[100720 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn import (TransformerDecoder, TransformerDecoderLayer,\n",
    "                      TransformerEncoder, TransformerEncoderLayer)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CommonDataset import Dataset\n",
    "\n",
    "\n",
    "class CloseDataset(Dataset):\n",
    "    \"\"\" \n",
    "\n",
    "    Args:\n",
    "        Dataset (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    def __init__(self, df, close_column, volume_columns=[], data_length=15, observation_length:int=15, device=\"cuda\", init_type=\"log\", future_step_size=1, seed=1017, is_training = True):\n",
    "        self.data_length = data_length\n",
    "        super().__init__(df, [close_column], volume_columns, observation_length, device, init_type, future_step_size, seed, is_training)\n",
    "        \n",
    "    def _init_indicies(self, data, split_ratio=0.7):\n",
    "        length = len(data) - self._future_step_size - self.data_length\n",
    "        if length <= 0:\n",
    "            raise Exception(f\"date length {length} is less than observation_length {self.observation_length}\")\n",
    "            \n",
    "        indices = random.sample(range(self.observation_length+1, length), k=length-self.observation_length-1)\n",
    "        \n",
    "        if self.is_training:\n",
    "            from_index = 0\n",
    "            to_index = int(length*split_ratio)\n",
    "        else:\n",
    "            from_index = int(length*split_ratio)+1\n",
    "            to_index = length\n",
    "        \n",
    "        self._indices = indices[from_index:to_index]\n",
    "        self._entire_indices = indices\n",
    "        \n",
    "    def _outputFunc(self, batch_size):\n",
    "        if type(batch_size) == int:\n",
    "            batch_size = slice(batch_size, batch_size+1)\n",
    "        batch_indices = batch_size\n",
    "        \n",
    "        chunk_data = []\n",
    "        for index in self._indices[batch_indices]:\n",
    "            f_data = []\n",
    "            for f_step in range(0, self._future_step_size):\n",
    "                f_data.append(self._data[self._columns][index + f_step: index + self.data_length + f_step].values.reshape(self.data_length * len(self._columns)).tolist())                \n",
    "            chunk_data.append(f_data)\n",
    "            \n",
    "        return torch.tensor(chunk_data, device=self.device, dtype=torch.float).transpose(0, 1)\n",
    "    \n",
    "    def _inputFunc(self, batch_size):\n",
    "        if type(batch_size) == int:\n",
    "            batch_size = slice(batch_size, batch_size+1)\n",
    "        batch_indices = batch_size\n",
    "        chunk_src = []\n",
    "        for index in self._indices[batch_indices]:\n",
    "            ob_src = []\n",
    "            for ob_step in range(self.observation_length, 0, -1):\n",
    "                ob_src.append(self._data[self._columns][index - ob_step: index - ob_step + self.data_length].values.reshape(self.data_length * len(self._columns)).tolist())\n",
    "            chunk_src.append(ob_src)\n",
    "        \n",
    "        return torch.tensor(chunk_src, device=self.device, dtype=torch.float).transpose(0, 1)\n",
    "\n",
    "    def eval(self):\n",
    "        split_ratio = 0.7\n",
    "        length = len(self._entire_indices)\n",
    "        from_index = int(length*split_ratio)+1\n",
    "        to_index = length - self._future_step_size\n",
    "        self._indices = self._entire_indices[from_index:to_index]\n",
    "        self.is_training = False\n",
    "            \n",
    "    def get_actual_index(self,ndx):\n",
    "        inputs = []\n",
    "        if type(ndx) == slice:\n",
    "            for index in self._indices[ndx]:\n",
    "                inputs.append(index)\n",
    "        else:\n",
    "            inputs = self._indices[ndx]\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b8f0c1964c2d42c360293b97c2bf126adadb09f88ab60c350427a278226bd93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
